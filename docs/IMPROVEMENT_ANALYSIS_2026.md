# –ê–Ω–∞–ª–∏–∑ —É–ª—É—á—à–µ–Ω–∏–π –¥–ª—è DMarket Telegram Bot

> üìÖ **–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: –Ø–Ω–≤–∞—Ä—å 2026  
> üìä **–ò—Å—Ç–æ—á–Ω–∏–∫**: –ê–Ω–∞–ª–∏–∑ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤ AI/Automation

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π](#–æ–±–∑–æ—Ä-–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π)
2. [–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—è–º](#—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏-–ø–æ-—É–ª—É—á—à–µ–Ω–∏—è–º)
3. [–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑](#–¥–µ—Ç–∞–ª—å–Ω—ã–π-–∞–Ω–∞–ª–∏–∑)
4. [–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#–ø–ª–∞–Ω-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
5. [–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤](#–æ—Ü–µ–Ω–∫–∞-–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤)

---

## üîç –û–±–∑–æ—Ä –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π

–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤—ã–¥–µ–ª–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:

| –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ | –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –±–æ—Ç–∞ |
|------------|----------|----------------------|
| **Anthropic Knowledge Bases** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å –¥–ª—è AI | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ |
| **xyOps** | –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–µ—Ä–≤–µ—Ä–æ–≤ | ‚≠ê‚≠ê‚≠ê‚≠ê –í—ã—Å–æ–∫–æ |
| **n8n** | Open-source workflow automation | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –£–∂–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ |
| **LFM2.5-1.2B-Thinking** | On-device reasoning –º–æ–¥–µ–ª—å | ‚≠ê‚≠ê‚≠ê –°—Ä–µ–¥–Ω–µ |
| **Awesome-Cheatsheets** | –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ –∏ —à–ø–∞—Ä–≥–∞–ª–∫–∏ | ‚≠ê‚≠ê –ù–∏–∑–∫–æ |

---

## üöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—è–º

### 1. üìö **Knowledge Base System (–í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)**

**–í–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ**: Anthropic Knowledge Bases –¥–ª—è Claude

**–ö–æ–Ω—Ü–µ–ø—Ü–∏—è**: –°–æ–∑–¥–∞—Ç—å —Å–∏—Å—Ç–µ–º—É "—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏" –¥–ª—è –±–æ—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
- –ó–∞–ø–æ–º–∏–Ω–∞—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —Ç–æ—Ä–≥–æ–≤–ª–µ
- –°–æ—Ö—Ä–∞–Ω—è—Ç—å —É—Å–ø–µ—à–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- –•—Ä–∞–Ω–∏—Ç—å "–∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —É—Ä–æ–∫–∏" –∏–∑ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
- –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ –ø—Ä–æ–µ–∫—Ç–µ**:

```python
# src/utils/knowledge_base.py

from dataclasses import dataclass, field
from datetime import datetime, UTC
from enum import StrEnum
from typing import Any
from uuid import uuid4
import structlog
from pydantic import BaseModel

logger = structlog.get_logger(__name__)


class KnowledgeType(StrEnum):
    """Types of knowledge entries."""
    USER_PREFERENCE = "user_preference"      # –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    TRADING_PATTERN = "trading_pattern"       # –£—Å–ø–µ—à–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    LESSON_LEARNED = "lesson_learned"         # –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —É—Ä–æ–∫–∏
    MARKET_INSIGHT = "market_insight"         # –ò–Ω—Å–∞–π—Ç—ã –æ —Ä—ã–Ω–∫–µ
    PRICE_ANOMALY = "price_anomaly"           # –ê–Ω–æ–º–∞–ª–∏–∏ —Ü–µ–Ω


@dataclass
class KnowledgeEntry:
    """Single knowledge entry."""
    id: str
    user_id: int
    knowledge_type: KnowledgeType
    content: dict[str, Any]
    relevance_score: float = 1.0  # –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å (0-1)
    created_at: datetime = field(default_factory=lambda: datetime.now(UTC))
    last_used_at: datetime | None = None
    use_count: int = 0


class KnowledgeBase:
    """User-specific knowledge base for trading insights.
    
    Inspired by Anthropic's Knowledge Bases concept - proactive
    context checking and automatic knowledge accumulation.
    """
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self._entries: dict[str, KnowledgeEntry] = {}
        self._relevance_decay_rate = 0.01  # –°–∫–æ—Ä–æ—Å—Ç—å "–∑–∞–±—ã–≤–∞–Ω–∏—è"
    
    async def add_knowledge(
        self,
        knowledge_type: KnowledgeType,
        content: dict[str, Any],
        relevance_score: float = 1.0,
    ) -> str:
        """Add new knowledge entry.
        
        Automatically called when:
        - User completes a successful trade
        - Pattern detected in trading history
        - Anomaly detected in market
        """
        entry_id = f"{self.user_id}_{knowledge_type}_{uuid4().hex[:8]}"
        
        entry = KnowledgeEntry(
            id=entry_id,
            user_id=self.user_id,
            knowledge_type=knowledge_type,
            content=content,
            relevance_score=relevance_score,
        )
        
        self._entries[entry_id] = entry
        
        logger.info(
            "knowledge_added",
            user_id=self.user_id,
            type=knowledge_type,
            entry_id=entry_id,
        )
        
        return entry_id
    
    async def query_relevant(
        self,
        context: dict[str, Any],
        min_relevance: float = 0.5,
        limit: int = 10,
    ) -> list[KnowledgeEntry]:
        """Query knowledge base for relevant entries.
        
        Proactively checks knowledge base when:
        - Analyzing new arbitrage opportunity
        - Making trade recommendation
        - User asks about specific item
        """
        # Filter by relevance
        relevant = [
            e for e in self._entries.values()
            if e.relevance_score >= min_relevance
        ]
        
        # Score by context match
        scored = []
        for entry in relevant:
            score = self._calculate_context_match(entry, context)
            scored.append((entry, score))
        
        # Sort and limit
        scored.sort(key=lambda x: x[1], reverse=True)
        
        results = [e for e, _ in scored[:limit]]
        
        # Update usage stats
        for entry in results:
            entry.last_used_at = datetime.now(UTC)
            entry.use_count += 1
        
        return results
    
    async def learn_from_trade(
        self,
        trade_result: dict[str, Any],
    ) -> None:
        """Automatically learn from trade outcome.
        
        Called after every trade to extract lessons:
        - If profitable: record successful pattern
        - If loss: record lesson learned
        - Always: update market insights
        """
        profit = trade_result.get("profit", 0)
        item = trade_result.get("item_name", "")
        
        if profit > 0:
            await self.add_knowledge(
                KnowledgeType.TRADING_PATTERN,
                {
                    "item": item,
                    "pattern": "profitable_trade",
                    "details": trade_result,
                    "learned": f"Item {item} was profitable with {profit:.2f}% margin",
                },
            )
        else:
            await self.add_knowledge(
                KnowledgeType.LESSON_LEARNED,
                {
                    "item": item,
                    "lesson": "avoid_similar",
                    "details": trade_result,
                    "learned": f"Avoid {item} - resulted in {profit:.2f}% loss",
                },
            )
    
    def _calculate_context_match(
        self,
        entry: KnowledgeEntry,
        context: dict[str, Any],
    ) -> float:
        """Calculate how well an entry matches the context."""
        score = entry.relevance_score
        
        # Match by item name
        entry_item = entry.content.get("item")
        context_item = context.get("item")
        if entry_item and context_item:
            if entry_item.lower() in context_item.lower():
                score *= 2.0
        
        # Match by game
        if "game" in entry.content and "game" in context:
            if entry.content["game"] == context["game"]:
                score *= 1.5
        
        # Boost recent entries
        if entry.last_used_at:
            days_ago = (datetime.now(UTC) - entry.last_used_at).days
            recency_boost = max(0.1, 1.0 - (days_ago * 0.1))
            score *= recency_boost
        
        return score
    
    async def decay_relevance(self) -> int:
        """Apply relevance decay to all entries.
        
        Called periodically to "forget" outdated knowledge.
        Returns number of entries removed.
        """
        removed = 0
        to_remove = []
        
        for entry_id, entry in self._entries.items():
            entry.relevance_score *= (1 - self._relevance_decay_rate)
            
            if entry.relevance_score < 0.1:
                to_remove.append(entry_id)
        
        for entry_id in to_remove:
            del self._entries[entry_id]
            removed += 1
        
        if removed > 0:
            logger.info(
                "knowledge_decay_applied",
                user_id=self.user_id,
                removed_count=removed,
            )
        
        return removed
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–æ–¥—É–ª—è–º–∏**:
- `src/ml/price_predictor.py` - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- `src/dmarket/arbitrage_scanner.py` - —É—á–∏—Ç—ã–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- `src/telegram_bot/handlers/` - –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

---

### 2. ü§ñ **xyOps-inspired Incident Management (–°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)**

**–í–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ**: xyOps - —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞**:
- ‚úÖ –ï—Å—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —á–µ—Ä–µ–∑ Prometheus (`src/utils/prometheus_metrics.py`)
- ‚úÖ –ï—Å—Ç—å –∞–ª–µ—Ä—Ç—ã —á–µ—Ä–µ–∑ Sentry (`src/utils/sentry_integration.py`)
- ‚úÖ –ï—Å—Ç—å health checks (`src/utils/health_check.py`)
- ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã
- ‚ùå –ù–µ—Ç —Å–∏—Å—Ç–µ–º—ã —Ç–∏–∫–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–±–ª–µ–º

**–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è**:

```python
# src/utils/incident_manager.py

from dataclasses import dataclass, field
from datetime import datetime, UTC
from enum import StrEnum
from typing import Any, Callable
import asyncio
import structlog

logger = structlog.get_logger(__name__)


class IncidentSeverity(StrEnum):
    """Severity levels for incidents."""
    LOW = "low"           # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ
    MEDIUM = "medium"     # –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è
    HIGH = "high"         # –¢—Ä–µ–±—É–µ—Ç –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    CRITICAL = "critical" # –¢—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞


class IncidentStatus(StrEnum):
    """Status of an incident."""
    DETECTED = "detected"
    ACKNOWLEDGED = "acknowledged"
    INVESTIGATING = "investigating"
    MITIGATING = "mitigating"
    RESOLVED = "resolved"


@dataclass
class Incident:
    """Represents a system incident."""
    id: str
    title: str
    description: str
    severity: IncidentSeverity
    source: str  # monitoring, api, user_report
    status: IncidentStatus = IncidentStatus.DETECTED
    detected_at: datetime = field(default_factory=lambda: datetime.now(UTC))
    resolved_at: datetime | None = None
    auto_mitigated: bool = False
    metadata: dict[str, Any] = field(default_factory=dict)


class IncidentManager:
    """xyOps-inspired incident management system.
    
    Combines:
    - Real-time monitoring
    - Alerting
    - Automatic mitigation
    - Incident tracking
    """
    
    def __init__(self):
        self._incidents: dict[str, Incident] = {}
        self._mitigation_handlers: dict[str, Callable] = {}
        self._alert_channels: list[Callable] = []
        self._incident_counter = 0
    
    def register_mitigation_handler(
        self,
        incident_type: str,
        handler: Callable[[Incident], bool],
    ) -> None:
        """Register automatic mitigation handler.
        
        Handler returns True if mitigation was successful.
        """
        self._mitigation_handlers[incident_type] = handler
        logger.info("mitigation_handler_registered", type=incident_type)
    
    def register_alert_channel(
        self,
        channel: Callable[[Incident], None],
    ) -> None:
        """Register alert notification channel."""
        self._alert_channels.append(channel)
    
    async def detect_incident(
        self,
        title: str,
        description: str,
        severity: IncidentSeverity,
        source: str,
        incident_type: str = "generic",
        metadata: dict[str, Any] | None = None,
    ) -> Incident:
        """Detect and register a new incident.
        
        Automatically:
        1. Creates incident record
        2. Sends alerts
        3. Attempts auto-mitigation if handler exists
        """
        self._incident_counter += 1
        incident_id = f"INC-{self._incident_counter:05d}"
        
        incident = Incident(
            id=incident_id,
            title=title,
            description=description,
            severity=severity,
            source=source,
            metadata=metadata or {},
        )
        
        self._incidents[incident_id] = incident
        
        logger.warning(
            "incident_detected",
            incident_id=incident_id,
            title=title,
            severity=severity.value,
        )
        
        # Send alerts
        await self._send_alerts(incident)
        
        # Attempt auto-mitigation
        if incident_type in self._mitigation_handlers:
            await self._attempt_mitigation(incident, incident_type)
        
        return incident
    
    async def _send_alerts(self, incident: Incident) -> None:
        """Send alerts through all registered channels."""
        for channel in self._alert_channels:
            try:
                if asyncio.iscoroutinefunction(channel):
                    await channel(incident)
                else:
                    channel(incident)
            except Exception as e:
                logger.error(
                    "alert_channel_failed",
                    incident_id=incident.id,
                    error=str(e),
                )
    
    async def _attempt_mitigation(
        self,
        incident: Incident,
        incident_type: str,
    ) -> bool:
        """Attempt automatic mitigation."""
        handler = self._mitigation_handlers.get(incident_type)
        if not handler:
            return False
        
        incident.status = IncidentStatus.MITIGATING
        
        try:
            if asyncio.iscoroutinefunction(handler):
                success = await handler(incident)
            else:
                success = handler(incident)
            
            if success:
                incident.status = IncidentStatus.RESOLVED
                incident.resolved_at = datetime.now(UTC)
                incident.auto_mitigated = True
                
                logger.info(
                    "incident_auto_mitigated",
                    incident_id=incident.id,
                )
            else:
                incident.status = IncidentStatus.INVESTIGATING
            
            return success
            
        except Exception as e:
            logger.error(
                "auto_mitigation_failed",
                incident_id=incident.id,
                error=str(e),
            )
            incident.status = IncidentStatus.INVESTIGATING
            return False
    
    async def resolve_incident(
        self,
        incident_id: str,
        resolution_notes: str = "",
    ) -> bool:
        """Manually resolve an incident."""
        if incident_id not in self._incidents:
            return False
        
        incident = self._incidents[incident_id]
        incident.status = IncidentStatus.RESOLVED
        incident.resolved_at = datetime.now(UTC)
        incident.metadata["resolution_notes"] = resolution_notes
        
        logger.info(
            "incident_resolved",
            incident_id=incident_id,
            notes=resolution_notes,
        )
        
        return True
    
    def get_active_incidents(
        self,
        severity: IncidentSeverity | None = None,
    ) -> list[Incident]:
        """Get all active (unresolved) incidents."""
        active = [
            i for i in self._incidents.values()
            if i.status != IncidentStatus.RESOLVED
        ]
        
        if severity:
            active = [i for i in active if i.severity == severity]
        
        return sorted(active, key=lambda i: i.detected_at, reverse=True)


# Example mitigation handlers for trading bot
async def mitigate_rate_limit(incident: Incident) -> bool:
    """Automatic rate limit mitigation."""
    # Reduce request rate
    from src.utils.rate_limiter import get_rate_limiter
    
    limiter = get_rate_limiter()
    limiter.reduce_rate(factor=0.5)
    
    return True


async def mitigate_api_timeout(incident: Incident) -> bool:
    """Automatic API timeout mitigation."""
    # Switch to fallback endpoint or increase timeout
    return True
```

**–°–≤—è–∑—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–æ–¥—É–ª—è–º–∏**:
- `src/utils/api_circuit_breaker.py` - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Circuit Breaker
- `src/utils/health_monitor.py` - –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
- `src/utils/sentry_integration.py` - –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤

---

### 3. üîó **–£–ª—É—á—à–µ–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å n8n (–°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)**

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ**: 
- ‚úÖ –ï—Å—Ç—å –ø–∞–ø–∫–∞ `n8n/` —Å workflows
- ‚úÖ –ï—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è `docs/N8N_*`
- ‚ùå –ù–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏–∑ Python

**–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è**:

```python
# src/utils/n8n_client.py

import httpx
import structlog
from dataclasses import dataclass
from typing import Any

logger = structlog.get_logger(__name__)


@dataclass
class N8NWorkflow:
    """N8N workflow representation."""
    id: str
    name: str
    active: bool
    webhook_url: str | None = None


class N8NClient:
    """Client for n8n workflow automation.
    
    Enables:
    - Triggering workflows programmatically
    - Managing workflow state
    - Receiving webhook callbacks
    """
    
    def __init__(
        self,
        base_url: str = "http://localhost:5678",
        api_key: str | None = None,
    ):
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self._client: httpx.AsyncClient | None = None
    
    async def __aenter__(self):
        headers = {}
        if self.api_key:
            headers["X-N8N-API-KEY"] = self.api_key
        
        self._client = httpx.AsyncClient(
            base_url=self.base_url,
            headers=headers,
            timeout=30.0,
        )
        return self
    
    async def __aexit__(self, *args):
        if self._client:
            await self._client.aclose()
    
    async def trigger_workflow(
        self,
        workflow_id: str,
        data: dict[str, Any] | None = None,
    ) -> dict[str, Any]:
        """Trigger a workflow execution.
        
        Use cases:
        - Trigger arbitrage alert workflow
        - Trigger trade execution workflow
        - Trigger report generation
        """
        if not self._client:
            raise RuntimeError("Client not initialized. Use async context manager.")
        
        response = await self._client.post(
            f"/api/v1/workflows/{workflow_id}/execute",
            json=data or {},
        )
        response.raise_for_status()
        
        logger.info(
            "n8n_workflow_triggered",
            workflow_id=workflow_id,
        )
        
        return response.json()
    
    async def send_webhook(
        self,
        webhook_path: str,
        data: dict[str, Any],
    ) -> dict[str, Any]:
        """Send data to n8n webhook.
        
        Used for:
        - Sending arbitrage opportunities
        - Triggering alerts
        - Syncing trade data
        """
        if not self._client:
            raise RuntimeError("Client not initialized.")
        
        response = await self._client.post(
            f"/webhook/{webhook_path}",
            json=data,
        )
        response.raise_for_status()
        
        return response.json()
    
    async def list_workflows(self) -> list[N8NWorkflow]:
        """List all available workflows."""
        if not self._client:
            raise RuntimeError("Client not initialized.")
        
        response = await self._client.get("/api/v1/workflows")
        response.raise_for_status()
        
        workflows = []
        for w in response.json().get("data", []):
            workflows.append(N8NWorkflow(
                id=w["id"],
                name=w["name"],
                active=w.get("active", False),
                webhook_url=w.get("webhookUrl"),
            ))
        
        return workflows


# Pre-defined workflow triggers for trading bot
class TradingWorkflows:
    """Pre-configured workflow triggers for trading operations."""
    
    ARBITRAGE_ALERT = "arbitrage-alert"
    DAILY_REPORT = "daily-report"
    TRADE_NOTIFICATION = "trade-notification"
    PRICE_ALERT = "price-alert"
    
    @staticmethod
    async def trigger_arbitrage_alert(
        client: N8NClient,
        opportunity: dict[str, Any],
    ) -> None:
        """Trigger arbitrage alert workflow."""
        await client.send_webhook(
            TradingWorkflows.ARBITRAGE_ALERT,
            {
                "type": "arbitrage",
                "item": opportunity.get("item_name"),
                "profit_percent": opportunity.get("profit_percent"),
                "buy_price": opportunity.get("buy_price"),
                "sell_price": opportunity.get("sell_price"),
                "platform": opportunity.get("platform", "dmarket"),
                "timestamp": opportunity.get("timestamp"),
            },
        )
```

---

### 4. üß† **On-Device ML Model Integration (–ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)**

**–í–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ**: LFM2.5-1.2B-Thinking - on-device reasoning –º–æ–¥–µ–ª—å

**–ö–æ–Ω—Ü–µ–ø—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–µ reasoning –º–æ–¥–µ–ª–∏ –¥–ª—è:
- –ê–Ω–∞–ª–∏–∑–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π –æ—Ñ–ª–∞–π–Ω
- –û–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
- Tool use –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è** (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):

```python
# src/ml/on_device_reasoner.py

from dataclasses import dataclass
from typing import Any
import structlog

logger = structlog.get_logger(__name__)


@dataclass
class ReasoningResult:
    """Result of on-device reasoning."""
    answer: str
    thinking_trace: str  # Internal reasoning steps
    confidence: float
    tool_calls: list[dict[str, Any]] = field(default_factory=list)
    

class OnDeviceReasoner:
    """Lightweight on-device reasoning for trading decisions.
    
    Inspired by LFM2.5-1.2B-Thinking model capabilities:
    - Generates internal thinking traces
    - Optimized for tool use
    - Runs entirely on CPU/mobile
    
    Note: This is a placeholder for future integration with
    models like LFM, Phi-3, or similar lightweight LLMs.
    """
    
    def __init__(self, model_path: str | None = None):
        self.model_path = model_path
        self._model = None
        
        logger.info(
            "on_device_reasoner_initialized",
            model_path=model_path,
        )
    
    async def reason_about_trade(
        self,
        trade_data: dict[str, Any],
    ) -> ReasoningResult:
        """Reason about whether to execute a trade.
        
        Generates step-by-step thinking before decision.
        """
        # Placeholder - would integrate with actual model
        thinking = self._generate_thinking_trace(trade_data)
        decision = self._make_decision(trade_data, thinking)
        
        return ReasoningResult(
            answer=decision["answer"],
            thinking_trace=thinking,
            confidence=decision["confidence"],
            tool_calls=decision.get("tool_calls"),
        )
    
    def _generate_thinking_trace(
        self,
        trade_data: dict[str, Any],
    ) -> str:
        """Generate internal thinking trace.
        
        Mimics LFM2.5-1.2B-Thinking's approach of
        generating reasoning before answering.
        """
        # Thresholds for decision making
        HIGH_PROFIT_THRESHOLD = 10
        MODERATE_PROFIT_THRESHOLD = 5
        GOOD_LIQUIDITY_THRESHOLD = 0.7
        
        steps = []
        
        profit = trade_data.get("profit_percent", 0)
        if profit > HIGH_PROFIT_THRESHOLD:
            steps.append(f"Profit margin is {profit}%, which is high")
        elif profit > MODERATE_PROFIT_THRESHOLD:
            steps.append(f"Profit margin is {profit}%, which is moderate")
        else:
            steps.append(f"Profit margin is {profit}%, which is low")
        
        liquidity = trade_data.get("liquidity_score", 0)
        if liquidity > GOOD_LIQUIDITY_THRESHOLD:
            steps.append(f"Liquidity score {liquidity} indicates good market depth")
        else:
            steps.append(f"Liquidity score {liquidity} indicates potential issues")
        
        # Add more reasoning steps...
        
        return " -> ".join(steps)
    
    def _make_decision(
        self,
        trade_data: dict[str, Any],
        thinking: str,
    ) -> dict[str, Any]:
        """Make final decision based on reasoning."""
        # Decision thresholds (configurable)
        HIGH_PROFIT_THRESHOLD = 10
        MODERATE_PROFIT_THRESHOLD = 5
        GOOD_LIQUIDITY_THRESHOLD = 0.7
        ACCEPTABLE_LIQUIDITY_THRESHOLD = 0.5
        
        # Simple rule-based for now, would be ML model
        profit = trade_data.get("profit_percent", 0)
        liquidity = trade_data.get("liquidity_score", 0)
        
        if profit > HIGH_PROFIT_THRESHOLD and liquidity > GOOD_LIQUIDITY_THRESHOLD:
            return {
                "answer": "STRONG_BUY",
                "confidence": 0.9,
            }
        elif profit > MODERATE_PROFIT_THRESHOLD and liquidity > ACCEPTABLE_LIQUIDITY_THRESHOLD:
            return {
                "answer": "BUY",
                "confidence": 0.7,
            }
        else:
            return {
                "answer": "HOLD",
                "confidence": 0.5,
            }
```

---

## üìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑

### –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–æ–¥—É–ª—è–º–∏

| –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ | –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–æ–¥—É–ª—å | –°—Ç–µ–ø–µ–Ω—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ |
|------------------------|---------------------|-------------------|
| Knowledge Base | `src/utils/state_manager.py` | –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ |
| Knowledge Base | `src/ml/price_predictor.py` | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è |
| Incident Manager | `src/utils/api_circuit_breaker.py` | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è |
| Incident Manager | `src/utils/health_monitor.py` | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è |
| N8N Client | `n8n/workflows/` | –ù–æ–≤—ã–π –º–æ–¥—É–ª—å |
| On-Device Reasoner | `src/ml/` | –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ |

### –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

| –£–ª—É—á—à–µ–Ω–∏–µ | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –í—Ä–µ–º—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ | –¶–µ–Ω–Ω–æ—Å—Ç—å |
|-----------|-----------|------------------|----------|
| Knowledge Base | –í—ã—Å–æ–∫–∞—è | 2-3 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Incident Manager | –°—Ä–µ–¥–Ω—è—è | 1-2 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê‚≠ê‚≠ê |
| N8N Client | –ù–∏–∑–∫–∞—è | 3-5 –¥–Ω–µ–π | ‚≠ê‚≠ê‚≠ê |
| On-Device Reasoner | –í—ã—Å–æ–∫–∞—è | 3-4 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê‚≠ê |

---

## üìÖ –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –§–∞–∑–∞ 1: Knowledge Base System (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í—ã—Å–æ–∫–∏–π) ‚úÖ –í–´–ü–û–õ–ù–ï–ù–û

**–ó–∞–¥–∞—á–∏**:
1. [x] –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É `KnowledgeEntry` –∏ `KnowledgeBase`
2. [x] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö (PostgreSQL)
3. [x] –î–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Å–¥–µ–ª–æ–∫
4. [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å `ArbitrageScanner` –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
5. [x] –î–æ–±–∞–≤–∏—Ç—å Telegram –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
6. [x] –ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã (26 —Ç–µ—Å—Ç–æ–≤)

**–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã**:
- ‚úÖ `src/utils/knowledge_base.py` - –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å Knowledge Base
- ‚úÖ `src/models/knowledge.py` - SQLAlchemy –º–æ–¥–µ–ª–∏
- ‚úÖ `src/telegram_bot/handlers/knowledge_handler.py` - Telegram –∫–æ–º–∞–Ω–¥—ã
- ‚úÖ `tests/utils/test_knowledge_base.py` - 26 —Ç–µ—Å—Ç–æ–≤

### –§–∞–∑–∞ 2: Incident Management (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°—Ä–µ–¥–Ω–∏–π)

**–ó–∞–¥–∞—á–∏**:
1. [ ] –°–æ–∑–¥–∞—Ç—å `IncidentManager` –∫–ª–∞—Å—Å
2. [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
3. [ ] –î–æ–±–∞–≤–∏—Ç—å Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞—Ö
4. [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–∏—Ç–∏–≥–∞—Ü–∏–∏ –¥–ª—è —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
5. [ ] –î–æ–±–∞–≤–∏—Ç—å dashboard –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤

### –§–∞–∑–∞ 3: N8N Client (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ù–∏–∑–∫–∏–π)

**–ó–∞–¥–∞—á–∏**:
1. [ ] –°–æ–∑–¥–∞—Ç—å Python –∫–ª–∏–µ–Ω—Ç –¥–ª—è n8n API
2. [ ] –î–æ–±–∞–≤–∏—Ç—å pre-configured workflow triggers
3. [ ] –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

---

## üéØ –û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤

### –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤

```
–í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å ‚îÇ Knowledge Base ‚òÖ    ‚îÇ 
                 ‚îÇ                      ‚îÇ
–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–Ω–æ—Å—Ç—å ‚îÇ Incident Manager     ‚îÇ N8N Client
                 ‚îÇ                      ‚îÇ
–ù–∏–∑–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å  ‚îÇ                      ‚îÇ On-Device Reasoner
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                   –ù–∏–∑–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å      –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
```

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä—è–¥–æ–∫

1. **Knowledge Base System** - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å, —É–Ω–∏–∫–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
2. **Incident Manager** - —É–ª—É—á—à–∞–µ—Ç –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å –∏ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
3. **N8N Client** - –Ω–∏–∑–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å, —É–ª—É—á—à–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
4. **On-Device Reasoner** - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

---

## üìö –°—Å—ã–ª–∫–∏

- [Anthropic Knowledge Bases](https://docs.anthropic.com/) - –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ –¥–ª—è KB —Å–∏—Å—Ç–µ–º—ã
- [xyOps GitHub](https://github.com/pixlcore/xyops) - –ø—Ä–∏–º–µ—Ä incident management
- [n8n Documentation](https://docs.n8n.io/) - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è workflow
- [LFM Models](https://huggingface.co/liquid) - on-device reasoning

---

*–î–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π AI/Automation –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏—Ö –∫ —Ç–æ—Ä–≥–æ–≤–æ–º—É –±–æ—Ç—É DMarket.*
