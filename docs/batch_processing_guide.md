# Batch Processing Guide

**–î–∞—Ç–∞**: 17 –¥–µ–∫–∞–±—Ä—è 2025 –≥.
**–í–µ—Ä—Å–∏—è**: 1.0

---

## –û–±–∑–æ—Ä

–ú–æ–¥—É–ª—å `batch_processor.py` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –æ—á–µ—Ä–µ–¥–µ–π –∑–∞–¥–∞—á (Celery/RabbitMQ). –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è single-user —Ä–µ–∂–∏–º–∞.

## –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. Simple Batch Processing

- ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ N –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –∑–∞ —Ä–∞–∑
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è memory cleanup –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
- ‚úÖ Progress tracking —á–µ—Ä–µ–∑ callbacks
- ‚úÖ Error handling —Å graceful recovery

### 2. Concurrent Processing

- ‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á
- ‚úÖ Semaphore-based concurrency control
- ‚úÖ Automatic retry –Ω–∞ –æ—à–∏–±–∫–∞—Ö
- ‚úÖ Resource throttling

### 3. Progress Tracking

- ‚úÖ Real-time progress updates
- ‚úÖ Formatted progress strings
- ‚úÖ Telegram integration ready

---

## SimpleBatchProcessor

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from src.utils.batch_processor import SimpleBatchProcessor

async def process_market_items():
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–æ–ª—å—à–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤."""
    # –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤
    items = await api.get_all_market_items(game="csgo")  # 5000+ items

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å processor
    processor = SimpleBatchProcessor(
        batch_size=100,              # 100 –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –∑–∞ —Ä–∞–∑
        delay_between_batches=0.1    # 100ms –∑–∞–¥–µ—Ä–∂–∫–∞
    )

    # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ batch
    async def process_batch(batch):
        results = []
        for item in batch:
            # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞
            profit = calculate_arbitrage(item)
            if profit > 0:
                results.append({
                    "item": item["title"],
                    "profit": profit
                })
        return results

    # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –ø—Ä–µ–¥–º–µ—Ç—ã
    opportunities = await processor.process_in_batches(
        items=items,
        process_fn=process_batch
    )

    print(f"–ù–∞–π–¥–µ–Ω–æ {len(opportunities)} –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")
```

### –° progress tracking

```python
async def scan_with_progress(update: Update):
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞."""
    items = await get_items()
    processor = SimpleBatchProcessor(batch_size=100)

    # Progress message
    msg = await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ...")

    # Progress callback
    async def update_progress(processed, total):
        percent = (processed / total) * 100
        await msg.edit_text(
            f"üîÑ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {processed}/{total} ({percent:.1f}%)\n"
            f"‚è±Ô∏è –û—Å—Ç–∞–ª–æ—Å—å: {total - processed} –ø—Ä–µ–¥–º–µ—Ç–æ–≤"
        )

    # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å progress
    results = await processor.process_in_batches(
        items=items,
        process_fn=analyze_items,
        progress_callback=update_progress
    )

    await msg.edit_text(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ù–∞–π–¥–µ–Ω–æ: {len(results)}")
```

### Error handling

```python
async def robust_processing():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    processor = SimpleBatchProcessor(batch_size=50)

    # Error callback
    async def handle_error(error, failed_batch):
        logger.error(
            f"Batch failed: {error}",
            batch_size=len(failed_batch)
        )
        # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å failed batch –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        # await save_failed_batch(failed_batch)

    results = await processor.process_in_batches(
        items=items,
        process_fn=risky_operation,
        error_callback=handle_error  # –ù–µ –ø–∞–¥–∞—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    )
```

---

## Concurrent Processing

### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º

```python
async def concurrent_api_calls():
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ API –≤—ã–∑–æ–≤—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º."""
    processor = SimpleBatchProcessor()
    items = [...—Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤...]

    async def fetch_item_details(item):
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞."""
        return await api.get_item_details(item["id"])

    # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ 5 –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    details = await processor.process_with_concurrency(
        items=items,
        process_fn=fetch_item_details,
        max_concurrent=5  # –ù–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API
    )

    return details
```

### Real-world –ø—Ä–∏–º–µ—Ä: Bulk target creation

```python
async def create_targets_in_bulk(target_specs: list[dict]):
    """–°–æ–∑–¥–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–∞—Ä–≥–µ—Ç–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ."""
    processor = SimpleBatchProcessor(batch_size=10)  # DMarket –ª–∏–º–∏—Ç

    async def create_batch(batch):
        """–°–æ–∑–¥–∞—Ç—å batch —Ç–∞—Ä–≥–µ—Ç–æ–≤."""
        return await dmarket_api.create_targets(
            targets=[
                {
                    "Title": spec["title"],
                    "Price": {"Amount": spec["price"], "Currency": "USD"},
                    "Amount": 1
                }
                for spec in batch
            ]
        )

    results = await processor.process_in_batches(
        items=target_specs,
        process_fn=create_batch
    )

    return results
```

---

## ProgressTracker

### Standalone usage

```python
from src.utils.batch_processor import ProgressTracker

async def long_operation():
    """–î–ª–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è —Å progress tracking."""
    items = [...]  # 1000 –ø—Ä–µ–¥–º–µ—Ç–æ–≤
    tracker = ProgressTracker(
        total=len(items),
        update_interval=50  # –û–±–Ω–æ–≤–ª—è—Ç—å –∫–∞–∂–¥—ã–µ 50 –ø—Ä–µ–¥–º–µ—Ç–æ–≤
    )

    for i, item in enumerate(items):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞...
        process(item)

        # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress = tracker.update(i + 1)
        if progress:
            # progress –≤–µ—Ä–Ω–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 50 –ø—Ä–µ–¥–º–µ—Ç–æ–≤
            print(tracker.format_progress())
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Telegram

```python
async def scan_with_tracker(update: Update):
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å ProgressTracker."""
    items = await get_items()
    tracker = ProgressTracker(total=len(items), update_interval=100)

    msg = await update.message.reply_text("üîÑ –ó–∞–ø—É—Å–∫...")

    for i, item in enumerate(items):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞
        result = await analyze_item(item)

        # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress = tracker.update(i + 1)
        if progress:
            # –û–±–Ω–æ–≤–∏—Ç—å Telegram —Å–æ–æ–±—â–µ–Ω–∏–µ
            await msg.edit_text(tracker.format_progress(i + 1))

    await msg.edit_text("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ!")
```

---

## Chunked API Calls

–î–ª—è —Ä–∞–±–æ—Ç—ã —Å rate-limited API:

```python
from src.utils.batch_processor import chunked_api_calls

async def fetch_aggregated_prices():
    """–ü–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—ã –¥–ª—è –º–Ω–æ–≥–∏—Ö –ø—Ä–µ–¥–º–µ—Ç–æ–≤."""
    items = ["AK-47 | Redline", "AWP | Asiimov", ...]  # 500 –ø—Ä–µ–¥–º–µ—Ç–æ–≤

    async def get_prices_batch(titles_batch):
        """API –≤—ã–∑–æ–≤ –¥–ª—è batch."""
        return await dmarket_api.get_aggregated_prices(
            game="csgo",
            titles=titles_batch
        )

    # –†–∞–∑–±–∏—Ç—å –Ω–∞ chunks –ø–æ 100 (DMarket –ª–∏–º–∏—Ç)
    all_prices = await chunked_api_calls(
        items=items,
        api_call_fn=get_prices_batch,
        chunk_size=100,
        delay=0.5  # 500ms –º–µ–∂–¥—É –≤—ã–∑–æ–≤–∞–º–∏
    )

    return all_prices
```

---

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ State Manager

–ö–æ–º–±–∏–Ω–∞—Ü–∏—è batch processing + state persistence:

```python
from src.utils.batch_processor import SimpleBatchProcessor
from src.utils.state_manager import StateManager
from uuid import uuid4

async def resilient_scan():
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å checkpoints –∏ batching."""
    scan_id = uuid4()
    processor = SimpleBatchProcessor(batch_size=100)

    async with get_session() as session:
        state = StateManager(session, checkpoint_interval=100)

        # –°–æ–∑–¥–∞—Ç—å checkpoint
        await state.create_checkpoint(
            scan_id=scan_id,
            user_id=user_id,
            operation_type="market_scan"
        )

        items = await get_items()
        processed_count = 0

        # Progress callback —Å checkpoint
        async def save_progress(processed, total):
            nonlocal processed_count
            processed_count = processed

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å checkpoint
            await state.save_checkpoint(
                scan_id=scan_id,
                processed_items=processed,
                total_items=total
            )

        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ checkpoints
        results = await processor.process_in_batches(
            items=items,
            process_fn=analyze_batch,
            progress_callback=save_progress
        )

        # –û—Ç–º–µ—Ç–∏—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        await state.mark_checkpoint_completed(scan_id)

        return results
```

---

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### Memory Management

```python
import gc

async def memory_efficient_processing():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π –ø–∞–º—è—Ç–∏."""
    processor = SimpleBatchProcessor(batch_size=100)

    async def process_batch(batch):
        results = []
        for item in batch:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞
            results.append(heavy_computation(item))

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞ –ø–æ—Å–ª–µ batch
        gc.collect()
        return results

    return await processor.process_in_batches(
        items=large_dataset,
        process_fn=process_batch
    )
```

### Resource Throttling

```python
import psutil

async def adaptive_processing():
    """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º —Ä–µ—Å—É—Ä—Å–æ–≤."""
    processor = SimpleBatchProcessor(batch_size=100)

    async def smart_batch_processor(batch):
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU
        cpu_percent = psutil.cpu_percent()

        if cpu_percent > 80:
            # –°–Ω–∏–∑–∏—Ç—å batch size
            mini_batches = [batch[i:i+20] for i in range(0, len(batch), 20)]
            results = []
            for mini in mini_batches:
                results.extend(await process_mini_batch(mini))
                await asyncio.sleep(0.5)  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            return results
        else:
            # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            return await process_normal_batch(batch)

    return await processor.process_in_batches(
        items=items,
        process_fn=smart_batch_processor
    )
```

---

## –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

### 1. –í—ã–±–æ—Ä batch_size

| –°—Ü–µ–Ω–∞—Ä–∏–π                 | Batch Size | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ             |
| ------------------------ | ---------- | ----------------------- |
| API calls (rate limited) | 10-50      | –ò–∑–±–µ–∂–∞—Ç—å rate limit     |
| Memory-intensive         | 20-50      | –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å OOM       |
| Fast operations          | 100-200    | –ú–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å overhead |
| Large datasets           | 50-100     | –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏/–ø–∞–º—è—Ç–∏  |

### 2. Delay Configuration

```python
# –î–ª—è API —Å rate limiting
processor = SimpleBatchProcessor(
    batch_size=50,
    delay_between_batches=0.5  # 500ms = –±–µ–∑–æ–ø–∞—Å–Ω–æ
)

# –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
processor = SimpleBatchProcessor(
    batch_size=200,
    delay_between_batches=0.01  # 10ms = –º–∏–Ω–∏–º–∞–ª—å–Ω–æ
)
```

### 3. Error Strategies

**Fail Fast** (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):

```python
# –ü—Ä–∏ –æ—à–∏–±–∫–µ - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å—ë
results = await processor.process_in_batches(
    items=items,
    process_fn=strict_operation
    # error_callback –ù–ï —É–∫–∞–∑–∞–Ω
)
```

**Continue on Error**:

```python
# –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
async def log_and_continue(error, batch):
    logger.error(f"Batch failed: {error}")
    # –ù–µ re-raise

results = await processor.process_in_batches(
    items=items,
    process_fn=lenient_operation,
    error_callback=log_and_continue
)
```

---

## –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –û–∂–∏–¥–∞–µ–º—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

- ‚úÖ **Throughput**: 100-500 items/second (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏)
- ‚úÖ **Memory Overhead**: <50MB –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
- ‚úÖ **CPU Usage**: <60% –Ω–∞ batch processing
- ‚úÖ **Latency**: <10ms overhead –Ω–∞ batch

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

```python
import time

async def monitored_processing():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º."""
    start_time = time.time()
    processor = SimpleBatchProcessor(batch_size=100)

    results = await processor.process_in_batches(
        items=items,
        process_fn=operation
    )

    duration = time.time() - start_time
    throughput = len(items) / duration

    logger.info(
        "Processing completed",
        total_items=len(items),
        duration_seconds=duration,
        throughput_items_per_sec=throughput
    )

    return results
```

---

## Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

**–†–µ—à–µ–Ω–∏–µ**: –£–≤–µ–ª–∏—á–∏—Ç—å batch_size –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å concurrent processing

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory

**–†–µ—à–µ–Ω–∏–µ**: –£–º–µ–Ω—å—à–∏—Ç—å batch_size, –¥–æ–±–∞–≤–∏—Ç—å gc.collect() –≤ process_fn

### –ü—Ä–æ–±–ª–µ–º–∞: Rate Limit Errors

**–†–µ—à–µ–Ω–∏–µ**: –£–≤–µ–ª–∏—á–∏—Ç—å delay_between_batches, —É–º–µ–Ω—å—à–∏—Ç—å batch_size

---

**–û–±–Ω–æ–≤–ª–µ–Ω–æ**: 17 –¥–µ–∫–∞–±—Ä—è 2025 –≥.
**–í–µ—Ä—Å–∏—è –º–æ–¥—É–ª—è**: 1.0
**–°—Ç–∞—Ç—É—Å**: Production Ready
