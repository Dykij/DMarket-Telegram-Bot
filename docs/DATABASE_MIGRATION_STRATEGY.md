# üóÑÔ∏è Database Migration Strategy

## –û–±–∑–æ—Ä

–°—Ç—Ä–∞—Ç–µ–≥–∏—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DMarket Telegram Bot —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Alembic.

## üéØ –ü—Ä–∏–Ω—Ü–∏–ø—ã

### 1. Backward Compatibility

**–í—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–≤–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏:**

‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–æ:**
```python
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ nullable –∫–æ–ª–æ–Ω–∫–∏
op.add_column('users', sa.Column('new_field', sa.String(), nullable=True))
```

‚ùå **–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ:**
```python
# NOT NULL –±–µ–∑ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
op.add_column('users', sa.Column('new_field', sa.String(), nullable=False))
```

### 2. Multi-Step Migrations

**–î–ª—è breaking changes –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤:**

**–®–∞–≥ 1**: –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É (nullable)
```python
op.add_column('users', sa.Column('email_new', sa.String(), nullable=True))
```

**–®–∞–≥ 2**: –ú–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
```python
op.execute("UPDATE users SET email_new = email WHERE email IS NOT NULL")
```

**–®–∞–≥ 3**: –°–¥–µ–ª–∞—Ç—å NOT NULL
```python
op.alter_column('users', 'email_new', nullable=False)
```

**–®–∞–≥ 4**: –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é –∫–æ–ª–æ–Ω–∫—É
```python
op.drop_column('users', 'email')
op.alter_column('users', 'email_new', new_column_name='email')
```

### 3. Zero-Downtime Deployment

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è Blue-Green –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π:**

1. **Deploy V1** —Å –æ–±—Ä–∞—Ç–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π –º–∏–≥—Ä–∞—Ü–∏–µ–π
2. **–ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é** –¥–∞–Ω–Ω—ã—Ö
3. **Deploy V2** —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
4. **Cleanup –º–∏–≥—Ä–∞—Ü–∏—è** —É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –ø–æ–ª—è

## üìã Checklist –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π

### Pre-Migration

- [ ] **Backup –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö**
  ```bash
  python scripts/backup_database.py --full
  ```

- [ ] **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–ø–∏–∏**
  ```bash
  python scripts/test_migration.py --migration-id abc123
  ```

- [ ] **Review –º–∏–≥—Ä–∞—Ü–∏–∏** –∫–æ–º–∞–Ω–¥–æ–π
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ breaking changes
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ constraints

- [ ] **Dry-run –º–∏–≥—Ä–∞—Ü–∏–∏**
  ```bash
  alembic upgrade head --sql > migration.sql
  # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å SQL –≤—Ä—É—á–Ω—É—é
  ```

### During Migration

- [ ] **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫**
  - Database connections
  - Query performance
  - Error rates

- [ ] **Communication**
  - –£–≤–µ–¥–æ–º–∏—Ç—å –∫–æ–º–∞–Ω–¥—É
  - Maintenance mode (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

### Post-Migration

- [ ] **Verify –¥–∞–Ω–Ω—ã–µ**
  ```bash
  python scripts/verify_migration.py --check-integrity
  ```

- [ ] **Performance —Ç–µ—Å—Ç—ã**
  ```bash
  python scripts/benchmark_queries.py
  ```

- [ ] **Rollback –ø–ª–∞–Ω –≥–æ—Ç–æ–≤**
  ```bash
  alembic downgrade -1
  ```

## üîí –¢–∏–ø—ã –º–∏–≥—Ä–∞—Ü–∏–π

### Type 1: Safe Migrations (No Downtime)

**–ü—Ä–∏–º–µ—Ä—ã:**
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ nullable –∫–æ–ª–æ–Ω–∫–∏
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ CONCURRENTLY (PostgreSQL)

**–ü—Ä–æ—Ü–µ—Å—Å:**
```bash
# 1. –°–æ–∑–¥–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é
alembic revision --autogenerate -m "add_user_preferences_table"

# 2. Review –∏ edit
vim alembic/versions/abc123_add_user_preferences_table.py

# 3. Test –Ω–∞ dev
alembic upgrade head

# 4. Deploy –±–µ–∑ downtime
python scripts/safe_migrate.py
```

### Type 2: Careful Migrations (Minimal Downtime)

**–ü—Ä–∏–º–µ—Ä—ã:**
- –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ–ª–æ–Ω–∫–∏
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ NOT NULL constraint
- –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏

**–ü—Ä–æ—Ü–µ—Å—Å:**
```bash
# 1. Multi-step migration
alembic revision -m "step1_add_new_column"
alembic revision -m "step2_migrate_data"
alembic revision -m "step3_drop_old_column"

# 2. Deploy –∫–∞–∂–¥—ã–π —à–∞–≥ –æ—Ç–¥–µ–ª—å–Ω–æ
alembic upgrade +1
# Wait and verify
alembic upgrade +1
# Wait and verify
alembic upgrade +1
```

### Type 3: Risky Migrations (Downtime Required)

**–ü—Ä–∏–º–µ—Ä—ã:**
- –ò–∑–º–µ–Ω–µ–Ω–∏–µ primary key
- –°–ª–æ–∂–Ω—ã–µ data migrations
- –†–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü

**–ü—Ä–æ—Ü–µ—Å—Å:**
```bash
# 1. Maintenance mode
python scripts/enable_maintenance.py

# 2. Full backup
python scripts/backup_database.py --full

# 3. Execute migration
alembic upgrade head

# 4. Verify extensively
python scripts/verify_migration.py --full-check

# 5. Disable maintenance
python scripts/disable_maintenance.py
```

## üõ†Ô∏è Safe Migration Patterns

### Adding Column

```python
def upgrade():
    # ‚úÖ Correct: nullable first
    op.add_column('users', sa.Column('telegram_username', sa.String(255), nullable=True))

    # Then populate
    op.execute("UPDATE users SET telegram_username = 'unknown' WHERE telegram_username IS NULL")

    # Then make NOT NULL
    op.alter_column('users', 'telegram_username', nullable=False)

def downgrade():
    op.drop_column('users', 'telegram_username')
```

### Renaming Column

```python
def upgrade():
    # Step 1: Add new column
    op.add_column('users', sa.Column('user_id', sa.BigInteger(), nullable=True))

    # Step 2: Copy data
    op.execute("UPDATE users SET user_id = telegram_id")

    # Step 3: Make NOT NULL
    op.alter_column('users', 'user_id', nullable=False)

    # Step 4: Create index before dropping old column
    op.create_index('ix_users_user_id', 'users', ['user_id'])

    # Step 5: Drop old (in next migration!)
    # op.drop_column('users', 'telegram_id')

def downgrade():
    op.add_column('users', sa.Column('telegram_id', sa.BigInteger(), nullable=True))
    op.execute("UPDATE users SET telegram_id = user_id")
    op.alter_column('users', 'telegram_id', nullable=False)
    op.drop_column('users', 'user_id')
```

### Changing Column Type

```python
def upgrade():
    # PostgreSQL: Use USING clause
    op.execute("""
        ALTER TABLE items
        ALTER COLUMN price
        TYPE DECIMAL(10,2)
        USING price::DECIMAL(10,2)
    """)

    # SQLite: Recreate table (handled by Alembic)
    with op.batch_alter_table('items') as batch_op:
        batch_op.alter_column('price',
            type_=sa.DECIMAL(10, 2),
            existing_type=sa.Integer())

def downgrade():
    # Reverse: –ø–æ—Ç–µ—Ä—è precision!
    op.execute("ALTER TABLE items ALTER COLUMN price TYPE INTEGER USING price::INTEGER")
```

### Adding Index

```python
def upgrade():
    # PostgreSQL: CONCURRENTLY to avoid table lock
    op.create_index(
        'ix_users_created_at',
        'users',
        ['created_at'],
        postgresql_concurrently=True
    )

def downgrade():
    op.drop_index('ix_users_created_at', 'users')
```

## üìä Data Integrity Checks

### Pre-Migration Checks

```python
# scripts/verify_migration.py

async def check_data_integrity(session: AsyncSession) -> dict[str, bool]:
    """Verify data integrity before migration."""
    checks = {}

    # Check 1: No orphaned records
    result = await session.execute(
        "SELECT COUNT(*) FROM targets WHERE user_id NOT IN (SELECT id FROM users)"
    )
    checks['no_orphans'] = result.scalar() == 0

    # Check 2: All prices positive
    result = await session.execute(
        "SELECT COUNT(*) FROM items WHERE price < 0"
    )
    checks['valid_prices'] = result.scalar() == 0

    # Check 3: Unique constraints
    result = await session.execute(
        "SELECT telegram_id, COUNT(*) FROM users GROUP BY telegram_id HAVING COUNT(*) > 1"
    )
    checks['unique_telegram_id'] = len(result.all()) == 0

    return checks
```

### Post-Migration Checks

```python
async def verify_migration_success(session: AsyncSession, migration_id: str) -> bool:
    """Verify migration completed successfully."""

    # Check 1: Row count unchanged (for data migrations)
    before_count = await get_table_count('users', before_migration=True)
    after_count = await get_table_count('users')

    if before_count != after_count:
        logger.error(f"Row count mismatch: {before_count} -> {after_count}")
        return False

    # Check 2: No NULL values in NOT NULL columns
    result = await session.execute(
        "SELECT COUNT(*) FROM users WHERE required_field IS NULL"
    )

    if result.scalar() > 0:
        logger.error("Found NULL values in NOT NULL column")
        return False

    return True
```

## üîÑ Rollback Strategy

### Automatic Rollback

```python
# scripts/safe_migrate.py

async def safe_migrate(target_revision: str = 'head') -> bool:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º rollback –ø—Ä–∏ –æ—à–∏–±–∫–µ.

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—Ç–∫–∞—Ç–∏–ª–∞—Å—å
    """
    # 1. Backup
    backup_file = await create_backup()
    logger.info(f"Backup created: {backup_file}")

    # 2. Pre-migration checks
    if not await check_data_integrity():
        logger.error("Pre-migration checks failed")
        return False

    current_revision = get_current_revision()

    try:
        # 3. Apply migration
        alembic_upgrade(target_revision)

        # 4. Post-migration checks
        if not await verify_migration_success(target_revision):
            raise MigrationVerificationError("Post-migration checks failed")

        logger.info(f"Migration {target_revision} completed successfully")
        return True

    except Exception as e:
        logger.error(f"Migration failed: {e}")

        # Automatic rollback
        logger.info(f"Rolling back to {current_revision}")
        alembic_downgrade(current_revision)

        # Verify rollback
        if await check_data_integrity():
            logger.info("Rollback successful")
        else:
            logger.critical("Rollback verification failed! Manual intervention required")
            await send_alert("CRITICAL: Migration rollback verification failed")

        return False
```

### Manual Rollback

```bash
# Rollback one migration
alembic downgrade -1

# Rollback to specific revision
alembic downgrade abc123

# Rollback all migrations
alembic downgrade base

# Show migration history
alembic history --verbose

# Current revision
alembic current
```

## üß™ Testing Migrations

### Local Testing

```bash
# 1. Create test database copy
python scripts/copy_prod_to_test.py

# 2. Test migration
alembic -c alembic_test.ini upgrade head

# 3. Run integration tests
pytest tests/integration/ -v

# 4. Benchmark queries
python scripts/benchmark_queries.py --before --after
```

### CI/CD Integration

```yaml
# .github/workflows/migration-test.yml
name: Test Database Migration

on:
  pull_request:
    paths:
      - 'alembic/versions/*.py'

jobs:
  test-migration:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_db
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run migration
        run: |
          alembic upgrade head

      - name: Verify migration
        run: |
          python scripts/verify_migration.py

      - name: Test rollback
        run: |
          alembic downgrade -1
          alembic upgrade head
```

## üìö Common Patterns

### Adding Foreign Key

```python
def upgrade():
    # 1. Add column (nullable first)
    op.add_column('targets', sa.Column('user_id', sa.Integer(), nullable=True))

    # 2. Populate from existing data
    op.execute("""
        UPDATE targets
        SET user_id = (SELECT id FROM users WHERE users.telegram_id = targets.telegram_id)
    """)

    # 3. Make NOT NULL
    op.alter_column('targets', 'user_id', nullable=False)

    # 4. Create index BEFORE foreign key (faster)
    op.create_index('ix_targets_user_id', 'targets', ['user_id'])

    # 5. Add foreign key constraint
    op.create_foreign_key(
        'fk_targets_user_id',
        'targets', 'users',
        ['user_id'], ['id'],
        ondelete='CASCADE'
    )
```

### Splitting Table

```python
def upgrade():
    # 1. Create new table
    op.create_table(
        'user_settings',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('language', sa.String(5)),
        sa.Column('notifications_enabled', sa.Boolean(), default=True)
    )

    # 2. Migrate data
    op.execute("""
        INSERT INTO user_settings (user_id, language, notifications_enabled)
        SELECT id, language, notifications_enabled FROM users
    """)

    # 3. Add foreign key
    op.create_foreign_key('fk_user_settings_user_id', 'user_settings', 'users', ['user_id'], ['id'])

    # 4. Drop old columns (in next migration!)
    # op.drop_column('users', 'language')
    # op.drop_column('users', 'notifications_enabled')
```

## ‚ö†Ô∏è Pitfalls to Avoid

### 1. –ù–µ –¥–µ–ª–∞—Ç—å –≤ –æ–¥–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏

‚ùå **–ò–∑–±–µ–≥–∞—Ç—å:**
```python
def upgrade():
    op.add_column('users', sa.Column('email', sa.String(), nullable=False))  # Fails if table not empty!
```

‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–æ:**
```python
def upgrade():
    op.add_column('users', sa.Column('email', sa.String(), nullable=True))
    op.execute("UPDATE users SET email = 'default@example.com' WHERE email IS NULL")
    op.alter_column('users', 'email', nullable=False)
```

### 2. –ù–µ –∑–∞–±—ã–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã

‚ùå **–ò–∑–±–µ–≥–∞—Ç—å:**
```python
def upgrade():
    op.drop_column('users', 'old_id')  # Index dropped automatically
    op.add_column('users', sa.Column('new_id', sa.Integer()))
    # Forgot to create index!
```

‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–æ:**
```python
def upgrade():
    op.add_column('users', sa.Column('new_id', sa.Integer()))
    op.create_index('ix_users_new_id', 'users', ['new_id'])
    op.drop_column('users', 'old_id')
```

### 3. –ù–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å downgrade

‚ùå **–ò–∑–±–µ–≥–∞—Ç—å:**
```python
def downgrade():
    pass  # Not implemented
```

‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–æ:**
```python
def downgrade():
    op.drop_index('ix_users_new_id')
    op.drop_column('users', 'new_id')
    op.add_column('users', sa.Column('old_id', sa.Integer()))
```

## üöÄ Deployment Workflow

### Production Migration Process

```mermaid
graph TD
    A[Create Migration] --> B[Local Testing]
    B --> C[Code Review]
    C --> D[Staging Deploy]
    D --> E[Staging Migration]
    E --> F{Tests Pass?}
    F -->|No| G[Rollback Staging]
    F -->|Yes| H[Production Backup]
    H --> I[Production Migration]
    I --> J{Verify Success?}
    J -->|No| K[Rollback Production]
    J -->|Yes| L[Monitor Metrics]
```

### Commands

```bash
# 1. Development
alembic revision --autogenerate -m "add_user_preferences"
alembic upgrade head

# 2. Staging
git push origin feature/add-user-preferences
# CI runs migration tests
# Manual review of SQL

# 3. Production
# Maintenance window (if needed)
python scripts/safe_migrate.py --target head
# Monitoring and verification
```

## üìñ Resources

- [Alembic Documentation](https://alembic.sqlalchemy.org/)
- [PostgreSQL Online DDL](https://www.postgresql.org/docs/current/sql-altertable.html)
- [Zero-Downtime Migrations](https://blog.codeship.com/zero-downtime-database-migrations/)
- [Database Reliability Engineering](https://www.oreilly.com/library/view/database-reliability-engineering/9781491925935/)

---

**–í–µ—Ä—Å–∏—è**: 1.0.0
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 17 –¥–µ–∫–∞–±—Ä—è 2025 –≥.
